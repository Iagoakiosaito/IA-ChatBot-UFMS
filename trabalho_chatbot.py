# -*- coding: utf-8 -*-
"""Trabalho_ChatBot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x6eKoYRuDveuJ17C0xyGpFXs2A_7fIQ3
"""

""" Trecho de código EXCLUSIVO para o Google Colab
from google.colab import drive 
drive.mount('/content/gdrive')
path = "/content/gdrive/MyDrive/Colab Notebooks/DataSets/"
"""

#Importação das bibliotecas utilizadas
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import RandomizedSearchCV
import pandas as pd
import numpy as np

#Tratamento do data set
url = "https://raw.githubusercontent.com/Iagoakiosaito/IA-ChatBot-UFMS/main/Chatter-DB.csv"
df=pd.read_csv(url)
df = df[df['Orador'].notna()]
df = df[df['Sentença'].notna()]
df = df[df['Intenção'].notna()]
df = df[(df.Orador == '<')]

#Transformador para BOW
vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.6, strip_accents='unicode')

x = vectorizer.fit_transform(df.Sentença)
y = np.array(df.Intenção)

loo = LeaveOneOut()
scores = []
for train, test in loo.split(x):
    x_train = x[train]
    y_train = y[train]
    x_test  = x[test]
    y_test  = y[test]
    model = KNeighborsClassifier(n_neighbors=9, weights= "distance")
    model.fit(x_train,y_train)
    pred = model.predict(x_test)
    scores.append(metrics.accuracy_score(y_test,pred))

text = '1 caderno'
inst = vectorizer.transform([text])
print(model.predict(inst))

"""#**Random Search**"""

parameters = {'n_neighbors':range(1,10),'weights':['uniform','distance']}

rs = RandomizedSearchCV(model,parameters,n_iter=10,refit=True)

rs.fit(x,y)

rs.best_params_

rs.best_score_

rs.best_estimator_
